{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0d98e978-4549-47f4-984f-85f183706479",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Relevance Inference\n",
    "This notebook takes in the extracted text from PDF preprocessing stage, the fine tuned relevance model from the training stage, and performs inference on the input text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c027591e-edf8-4b5b-8b29-1f74d20527da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import pathlib\n",
    "from src.models.relevance_infer import TextRelevanceInfer\n",
    "from config_farm_train import InferConfig\n",
    "import config\n",
    "from src.data.s3_communication import S3Communication, S3FileType\n",
    "from dotenv import load_dotenv\n",
    "import zipfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5532cf65-84d9-4790-bfa9-f58e89f7b771",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load credentials\n",
    "dotenv_dir = os.environ.get(\n",
    "    \"CREDENTIAL_DOTENV_DIR\", os.environ.get(\"PWD\", \"/opt/app-root/src\")\n",
    ")\n",
    "dotenv_path = pathlib.Path(dotenv_dir) / \"credentials.env\"\n",
    "if os.path.exists(dotenv_path):\n",
    "    load_dotenv(dotenv_path=dotenv_path, override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cd13d4d-925d-4be0-93f2-b1463cdd5d6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# init s3 connector\n",
    "s3c = S3Communication(\n",
    "    s3_endpoint_url=os.getenv(\"S3_ENDPOINT\"),\n",
    "    aws_access_key_id=os.getenv(\"S3_LANDING_ACCESS_KEY\"),\n",
    "    aws_secret_access_key=os.getenv(\"S3_LANDING_SECRET_KEY\"),\n",
    "    s3_bucket=os.getenv(\"S3_BUCKET\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75d26d30-1ec1-4343-a551-d0b27f825909",
   "metadata": {},
   "outputs": [],
   "source": [
    "infer_config = InferConfig(\"infer_demo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88d46b7b-f93a-4b2b-a631-39c05cbf81f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# When running in Automation using Elyra and Kubeflow Pipelines,\n",
    "# set AUTOMATION = 1 as an environment variable\n",
    "if os.getenv(\"AUTOMATION\"):\n",
    "    # extracted pdfs\n",
    "    if not os.path.exists(config.BASE_EXTRACTION_FOLDER):\n",
    "        config.BASE_EXTRACTION_FOLDER.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # inference results dir\n",
    "    if not os.path.exists(infer_config.result_dir['Text']):\n",
    "        pathlib.Path(infer_config.result_dir['Text']).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # load dir\n",
    "    if not os.path.exists(infer_config.load_dir['Text']):\n",
    "        pathlib.Path(infer_config.load_dir['Text']).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # download extracted pdfs from s3\n",
    "    s3c.download_files_in_prefix_to_dir(\n",
    "        config.BASE_EXTRACTION_S3_PREFIX,\n",
    "        config.BASE_EXTRACTION_FOLDER,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62fa59b1-4fc0-4e03-8d0b-9066d0643bbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_root = pathlib.Path(infer_config.load_dir['Text']).parent\n",
    "model_rel_zip = pathlib.Path(model_root, 'RELEVANCE.zip')\n",
    "s3c.download_file_from_s3(model_rel_zip, config.CHECKPOINT_S3_PREFIX, \"RELEVANCE.zip\")\n",
    "\n",
    "with zipfile.ZipFile(pathlib.Path(model_root, 'RELEVANCE.zip'), 'r') as z:\n",
    "    z.extractall(model_root)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caf22ac3-2a27-40ce-a59f-e1b7c96089af",
   "metadata": {},
   "source": [
    "However, we advise that you manually update the parameters in the corresponding config file\n",
    "\n",
    "`esg_data_pipeline/config/config_farm_trainer.py`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32da3ba2-6a6c-459f-be90-cd6ede593f47",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9d8dfe2-5b84-4b2a-ae90-03d14a2807a9",
   "metadata": {},
   "source": [
    "### Loading the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "750dcc9b-fd03-4f7e-91cc-f7350897ba43",
   "metadata": {},
   "source": [
    "The following cell will load the trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "394e543f-507b-4450-9493-f9e734186972",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(infer_config.load_dir)\n",
    "print(infer_config.extracted_dir)\n",
    "print(infer_config.result_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04a68cfa-d266-4846-9802-bbfb38376720",
   "metadata": {},
   "outputs": [],
   "source": [
    "kpi_df = s3c.download_df_from_s3(\n",
    "    \"aicoe-osc-demo/kpi_mapping\",\n",
    "    \"kpi_mapping.csv\",\n",
    "    filetype=S3FileType.CSV,\n",
    "    header=0,\n",
    ")\n",
    "kpi_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "992f3875-85dc-4bf2-ac01-59c107142de3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "component = TextRelevanceInfer(infer_config, kpi_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a51bdd61-ed72-491b-bf92-d3006761f3ba",
   "metadata": {},
   "source": [
    "### Prediction on a Single Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0522d7ba-538b-4503-8f11-2decbcb78244",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "input_text = \"The company is going to reduce 8% in gas production\"\n",
    "input_question = \"Is the company going to go green?\"\n",
    "component.run_text(input_text=input_text, input_question=input_question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83c465be-fd3b-4e31-9561-8d9a14fe22bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_text = \"The company is about semi conductors\"\n",
    "input_question = \"Is the company going to go green?\"\n",
    "component.run_text(input_text=input_text, input_question=input_question)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd60bba1-2a06-4067-baf0-04dd4220bc38",
   "metadata": {},
   "source": [
    "### Prediction on an Entire Folder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "924a1b23-011c-40e9-b04a-a8ce9fd896fb",
   "metadata": {},
   "source": [
    "`run_folder()` will make prediction on all the JSON files in the /data/extraction folder. This will take some time, based on the number of json files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "461d2c9f-be3a-4856-a956-d6d0f5694574",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "component.run_folder()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d78421f-ace9-4c19-ab0f-65e31fabcd06",
   "metadata": {},
   "source": [
    "The results are saved in a CSV. For each table, the extracted text, as well as the page number from the source pdf file are saved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ef54093-09ae-4fb9-bb77-6d71693a01ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "csvfiles = [f for f in glob.glob(infer_config.result_dir['Text'] + \"/*.csv\")]\n",
    "for i in range(len(csvfiles)):\n",
    "    f = csvfiles[i]\n",
    "    df_table_results = pd.read_csv(f)\n",
    "    if i < 5:\n",
    "        print(f\"for file {f}:\")\n",
    "        print(df_table_results.head(20))\n",
    "    else:\n",
    "        print (f\"and file {f} (len = {len(df_table_results)})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14ae0386-ae1c-4eff-b826-5e07d7f46f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.getenv(\"AUTOMATION\"):\n",
    "    # upload the predicted files to s3\n",
    "    s3c.upload_files_in_dir_to_prefix(\n",
    "        infer_config.result_dir['Text'],\n",
    "        config.BASE_INFER_RELEVANCE_S3_PREFIX\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5226fc3d-87dc-432a-a571-5109d0ecfc86",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "This notebook ran the _Relevance_ inference on a sample dataset and stored the output in a csv format."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
